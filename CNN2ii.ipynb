{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFT-Did26t-s",
        "outputId": "a0c42f7a-5b43-4f2b-94bb-fca32a8e9398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.1)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (3.8.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.6.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.68.1)\n",
            "Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras) (0.0.8)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras) (0.13.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (1.4.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.12.14)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras) (0.1.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n"
          ]
        }
      ],
      "source": [
        "pip install tensorflow keras matplotlib scikit-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YHEfeRiN6xr_",
        "outputId": "ac05edc1-7828-4ceb-95e8-9b69e46f99ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V25Kb74FB4pO",
        "outputId": "905ce21d-6345-4586-8f57-3002f4dc0ef3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing folder: Fproccessed\n",
            "Processing folder: Rprocessed\n",
            "Number of images loaded: 598\n",
            "Class distribution: Counter({1: 316, 0: 282})\n",
            "Number of images after augmentation per epoch: 448\n",
            "Epoch 1/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 4s/step - accuracy: 0.5441 - loss: 29.0002 - val_accuracy: 0.5000 - val_loss: 27.6515\n",
            "Epoch 2/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - accuracy: 0.5253 - loss: 28.1809 - val_accuracy: 0.5000 - val_loss: 27.8544\n",
            "Epoch 3/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.5051 - loss: 27.7509 - val_accuracy: 0.5000 - val_loss: 28.0691\n",
            "Epoch 4/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.5524 - loss: 26.9912 - val_accuracy: 0.5000 - val_loss: 27.0302\n",
            "Epoch 5/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.5582 - loss: 26.0261 - val_accuracy: 0.5000 - val_loss: 25.0750\n",
            "Epoch 6/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.4679 - loss: 25.3053 - val_accuracy: 0.5000 - val_loss: 26.8569\n",
            "Epoch 7/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - accuracy: 0.4850 - loss: 24.5987 - val_accuracy: 0.5000 - val_loss: 25.3513\n",
            "Epoch 8/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.5046 - loss: 23.9302 - val_accuracy: 0.5000 - val_loss: 23.6786\n",
            "Epoch 9/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.4854 - loss: 23.3532 - val_accuracy: 0.5000 - val_loss: 22.5515\n",
            "Epoch 10/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.4947 - loss: 22.6720 - val_accuracy: 0.5000 - val_loss: 26.3859\n",
            "Epoch 11/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.5286 - loss: 21.9830 - val_accuracy: 0.5000 - val_loss: 22.3428\n",
            "Epoch 12/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 4s/step - accuracy: 0.4899 - loss: 21.4812 - val_accuracy: 0.5000 - val_loss: 21.0374\n",
            "Epoch 13/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.5129 - loss: 20.8797 - val_accuracy: 0.5000 - val_loss: 27.8075\n",
            "Epoch 14/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m59s\u001b[0m 4s/step - accuracy: 0.4806 - loss: 20.1364 - val_accuracy: 0.5000 - val_loss: 26.2228\n",
            "Epoch 15/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - accuracy: 0.4977 - loss: 19.7664 - val_accuracy: 0.5000 - val_loss: 20.7012\n",
            "Epoch 16/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 4s/step - accuracy: 0.5250 - loss: 19.5281 - val_accuracy: 0.5000 - val_loss: 21.8884\n",
            "Epoch 17/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.5099 - loss: 19.3910 - val_accuracy: 0.5000 - val_loss: 19.5431\n",
            "Epoch 18/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.5163 - loss: 19.0433 - val_accuracy: 0.5000 - val_loss: 18.5568\n",
            "Epoch 19/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 4s/step - accuracy: 0.5426 - loss: 18.4077 - val_accuracy: 0.5000 - val_loss: 19.4971\n",
            "Epoch 20/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.4751 - loss: 18.1066 - val_accuracy: 0.5000 - val_loss: 17.6002\n",
            "Epoch 21/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.5007 - loss: 17.5599 - val_accuracy: 0.5000 - val_loss: 18.6699\n",
            "Epoch 22/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.5560 - loss: 17.2173 - val_accuracy: 0.5000 - val_loss: 19.1678\n",
            "Epoch 23/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 4s/step - accuracy: 0.4935 - loss: 16.7004 - val_accuracy: 0.5000 - val_loss: 18.3141\n",
            "Epoch 24/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.6156 - loss: 16.0970 - val_accuracy: 0.5000 - val_loss: 15.7138\n",
            "Epoch 25/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 4s/step - accuracy: 0.4849 - loss: 15.8135 - val_accuracy: 0.5000 - val_loss: 17.0264\n",
            "Epoch 26/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.5435 - loss: 15.4944 - val_accuracy: 0.5000 - val_loss: 19.0049\n",
            "Epoch 27/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 4s/step - accuracy: 0.5339 - loss: 15.9906 - val_accuracy: 0.5000 - val_loss: 17.8413\n",
            "Epoch 28/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 4s/step - accuracy: 0.5422 - loss: 16.2326 - val_accuracy: 0.5000 - val_loss: 16.2958\n",
            "Epoch 29/50\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 4s/step - accuracy: 0.5260 - loss: 16.0155 - val_accuracy: 0.3778 - val_loss: 15.8000\n",
            "Epoch 29: early stopping\n",
            "Restoring model weights from the end of the best epoch: 24.\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 519ms/step - accuracy: 0.4219 - loss: 15.7166\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 390ms/step - accuracy: 0.5228 - loss: 15.7080\n",
            "Training Accuracy: 0.4569\n",
            "Test Accuracy: 0.5222\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "from collections import Counter\n",
        "\n",
        "# Define the dataset directory and corrected folder names\n",
        "dataset_dir = '/content/drive/My Drive/ml_data[processed]/'\n",
        "class_dirs = {'Fproccessed': 0, 'Rprocessed': 1}  # Corrected folder name for fake images\n",
        "\n",
        "# Parameters\n",
        "IMG_SIZE = (128, 128)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# Load images and labels dynamically\n",
        "images, labels = [], []\n",
        "\n",
        "for folder_name, label in class_dirs.items():\n",
        "    folder_path = os.path.join(dataset_dir, folder_name)\n",
        "    if os.path.isdir(folder_path):\n",
        "        print(f\"Processing folder: {folder_name}\")\n",
        "        for img_file in os.listdir(folder_path):\n",
        "            img_path = os.path.join(folder_path, img_file)\n",
        "            try:\n",
        "                img = load_img(img_path, target_size=IMG_SIZE)\n",
        "                img_array = img_to_array(img) / 255.0\n",
        "                images.append(img_array)\n",
        "                labels.append(label)\n",
        "            except Exception as e:\n",
        "                print(f\"Error loading image {img_path}: {e}\")\n",
        "    else:\n",
        "        print(f\"Folder not found: {folder_path}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Print dataset statistics\n",
        "print(f\"Number of images loaded: {len(images)}\")\n",
        "print(\"Class distribution:\", Counter(labels))\n",
        "\n",
        "# Split into training, validation, and testing datasets\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(images, labels, test_size=0.3, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
        "\n",
        "# Data augmentation setup\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,  # Normalize pixels\n",
        "    rotation_range=90,\n",
        "    width_shift_range=0.5,\n",
        "    height_shift_range=0.5,\n",
        "    shear_range=0.5,\n",
        "    zoom_range=0.5,\n",
        "    brightness_range=[0.5, 1.5],\n",
        "    horizontal_flip=True,\n",
        "    vertical_flip=True,\n",
        "    fill_mode='reflect'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator()\n",
        "\n",
        "test_datagen = ImageDataGenerator()\n",
        "\n",
        "# Create data generators\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE)\n",
        "test_generator = test_datagen.flow(X_test, y_test, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Print dataset size after augmentation\n",
        "steps_per_epoch = len(train_generator) * BATCH_SIZE\n",
        "print(f\"Number of images after augmentation per epoch: {steps_per_epoch}\")\n",
        "\n",
        "# Define the model architecture\n",
        "model = Sequential([\n",
        "    Input(shape=(128, 128, 3)),\n",
        "\n",
        "    Conv2D(32, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.3),\n",
        "\n",
        "    Conv2D(64, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Conv2D(128, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    Conv2D(256, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2, 2)),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Conv2D(512, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Conv2D(1024, (3, 3), activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.5),\n",
        "\n",
        "    Flatten(),\n",
        "    Dense(1024, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.6),\n",
        "\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.001),  # Increased learning rate\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1)\n",
        "]\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    validation_data=val_generator,\n",
        "    epochs=50,  # Maximum epochs\n",
        "    callbacks=callbacks,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Evaluate the model on training data\n",
        "def evaluate_generator(generator, model):\n",
        "    results = model.evaluate(generator)\n",
        "    return results[1]  # Return accuracy\n",
        "\n",
        "train_accuracy = evaluate_generator(train_generator, model)\n",
        "test_loss, test_accuracy = model.evaluate(test_generator)\n",
        "\n",
        "# Print results\n",
        "print(f\"Training Accuracy: {train_accuracy:.4f}\")\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0UVhe9QJAg2B"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
